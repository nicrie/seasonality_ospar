{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Support\n",
    "This notebooked aims to provide a reproducable way to compute the quantitative statements made in the manuscript. \n",
    "\n",
    "We start by loading all relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import datatree as dt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "from utils.transformation import yeojohnson_inv\n",
    "\n",
    "\n",
    "YEAR = 2001\n",
    "SEASONS = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "QUANTITY = \"absolute\"\n",
    "VARIABLE = \"Plastic\"\n",
    "\n",
    "base_path = f\"data/gpr/{QUANTITY}/{VARIABLE}/{YEAR}/\"\n",
    "\n",
    "\n",
    "# In-situ Beach Litter (OSPAR)\n",
    "ospar = dt.open_datatree(\"data/beach_litter/ospar/preprocessed.zarr\", engine=\"zarr\")\n",
    "litter_o = ospar[\"/\".join([\"preprocessed/\", QUANTITY, VARIABLE])]\n",
    "litter_o = litter_o.sel(year=slice(YEAR, 2020)).dropna(\"beach_id\", **{\"how\": \"all\"})\n",
    "\n",
    "\n",
    "# Effect size, confidence etc.\n",
    "model_analysis = xr.open_dataset(base_path + \"effect_size_seasons.nc\")\n",
    "\n",
    "# Inference data for GP models\n",
    "idata = {}\n",
    "for s in SEASONS:\n",
    "    idata[s] = az.from_netcdf(base_path + f\"idata_{s}.nc\")\n",
    "\n",
    "\n",
    "# Posterior predictive of macroplastic\n",
    "model = dt.open_datatree(base_path + \"posterior_predictive.zarr\", engine=\"zarr\")\n",
    "posterior_litter = model[\"posterior_predictive\"][VARIABLE]\n",
    "# Lambda parameter for Yeo-Johnson transform\n",
    "lmbda = model[\"lambda_yeojohnson\"][\"lambda\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJF: 184.0 (53.0; 352.0)\n",
      "MAM: 232.0 (79.0; 440.0)\n",
      "JJA: 154.0 (56.0; 290.0)\n",
      "SON: 174.0 (73.0; 332.0)\n"
     ]
    }
   ],
   "source": [
    "for season in SEASONS:\n",
    "    post = idata[season][\"posterior\"]\n",
    "    post_trans = yeojohnson_inv(post[\"mu_mu\"], lmbda)\n",
    "    lower, higher = pm.hdi(post_trans, hdi_prob=0.95).round(0)[\"mu_mu\"]\n",
    "    q025, q050, q975 = post_trans.quantile([.025, 0.5, 0.975]).round(0)\n",
    "    print(\"{:}: {:} ({:}; {:})\".format(season, q050.item(), lower.item(), higher.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJF\n",
      "eta_1: 1.08 (0.92; 1.23)\n",
      "eta_2: 0.64 (0.33; 0.93)\n",
      "rho_1: 15.75 (10.39; 22.68)\n",
      "rho_2: 777.24 (235.97; 1965.01)\n",
      "phi: 1.51 (1.37; 1.66)\n",
      "\n",
      "\n",
      "MAM\n",
      "eta_1: 1.19 (1.02; 1.38)\n",
      "eta_2: 0.72 (0.42; 1.04)\n",
      "rho_1: 15.65 (10.03; 22.38)\n",
      "rho_2: 507.78 (214.84; 1096.64)\n",
      "phi: 1.36 (1.25; 1.48)\n",
      "\n",
      "\n",
      "JJA\n",
      "eta_1: 1.08 (0.94; 1.24)\n",
      "eta_2: 0.65 (0.36; 0.97)\n",
      "rho_1: 11.92 (7.18; 17.06)\n",
      "rho_2: 593.49 (205.86; 1451.73)\n",
      "phi: 1.54 (1.41; 1.68)\n",
      "\n",
      "\n",
      "SON\n",
      "eta_1: 1.06 (0.93; 1.21)\n",
      "eta_2: 0.6 (0.33; 0.9)\n",
      "rho_1: 8.99 (5.68; 12.91)\n",
      "rho_2: 690.09 (227.93; 1933.8)\n",
      "phi: 1.53 (1.41; 1.66)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_vars = [\"eta_1\", \"eta_2\", \"rho_1\", \"rho_2\", \"phi\"]\n",
    "# print(idata[\"DJF\"].posterior.data_vars)\n",
    "for season in SEASONS:\n",
    "    print(season)\n",
    "    post = idata[season][\"posterior\"]\n",
    "    hdi = pm.hdi(post, hdi_prob=0.95).round(2)\n",
    "    vars_q050 = post.quantile(0.5).round(2)\n",
    "    for v in check_vars:\n",
    "        print(f\"{v}: \", end=\"\")\n",
    "        lower = hdi[v].sel(hdi=\"lower\").item()\n",
    "        higher = hdi[v].sel(hdi=\"higher\").item()        \n",
    "        q050 = vars_q050[v].item()\n",
    "        print(\"{:} ({:}; {:})\".format(q050, lower, higher))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beaches with significant seasonal variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant at 95%: 25\n",
      "Significant at 80%: 66\n",
      "Fraction of significant differences (95%): 0.149\n",
      "Fraction of significant differences (80%): 0.393\n"
     ]
    }
   ],
   "source": [
    "n_beaches = model_analysis.beach_id.size\n",
    "\n",
    "confidence_seaosonal_difference = model_analysis.max_hdi.max(\"combination\")\n",
    "\n",
    "sig_at_95 = (confidence_seaosonal_difference > 0.95).sum().item()\n",
    "sig_at_80 = (confidence_seaosonal_difference > 0.80).sum().item()\n",
    "\n",
    "print(f\"Significant at 95%: {sig_at_95}\")\n",
    "print(f\"Significant at 80%: {sig_at_80}\")\n",
    "\n",
    "print(f\"Fraction of significant differences (95%): {sig_at_95 / n_beaches:.3f}\")\n",
    "print(f\"Fraction of significant differences (80%): {sig_at_80 / n_beaches:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of significant differences (95%): 0.119\n",
      "Fraction of significant differences (80%): 0.238\n"
     ]
    }
   ],
   "source": [
    "sig_at_95 = (model_analysis.pvals_cr_mann_whitney.min(\"combination\") < 0.05).sum().item()\n",
    "sig_at_80 =( model_analysis.pvals_cr_mann_whitney.min(\"combination\") < 0.2).sum().item()\n",
    "\n",
    "print(f\"Fraction of significant differences (95%): {sig_at_95 / n_beaches:.3f}\")\n",
    "print(f\"Fraction of significant differences (80%): {sig_at_80 / n_beaches:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What share of beaches are spatially independent?\n",
    "\n",
    "We assume $3\\rho$ (short length scale) to be the distance beyond which spatial autocorrelation doesn't not play an important role anymore. First, we have to compute the pairwise distance matrix for all beaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of beaches which can be considered spatially independent in our dataset\n",
      "DJF: 0.232\n",
      "MAM: 0.232\n",
      "JJA: 0.327\n",
      "SON: 0.399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import numpy as np  \n",
    "\n",
    "lats = litter_o.lat.values\n",
    "lons = litter_o.lon.values\n",
    "\n",
    "rads_y = np.radians(lats)\n",
    "rads_x = np.radians(lons)\n",
    "\n",
    "distance_matrix = haversine_distances(list(zip(rads_y, rads_x))) * 6371\n",
    "\n",
    "rho_autumn = idata[\"SON\"][\"posterior\"][\"rho_1\"].median().item()\n",
    "\n",
    "print(\"Fraction of beaches which can be considered spatially independent in our dataset\")\n",
    "for season in SEASONS:\n",
    "    rho = idata[season][\"posterior\"][\"rho_1\"].median().item()\n",
    "    is_within_influence = distance_matrix < 3*rho\n",
    "    n_beaches_within_influence = is_within_influence.sum(0) - 1  # Minus 1 to exclude the beach itself\n",
    "    fraction_within_influence = (n_beaches_within_influence == 0).mean()\n",
    "    print(f\"{season}: {fraction_within_influence:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basura",
   "language": "python",
   "name": "basura"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
